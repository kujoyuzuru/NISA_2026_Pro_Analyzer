import streamlit as st
import pandas as pd
import yfinance as yf
import requests  # â˜…ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä»£ã‚ã‚Šã«ã“ã‚Œã‚’ä½¿ã†
import json
import os
import sqlite3
import ta
import time
import sys
from datetime import datetime, timedelta

# --- ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
st.set_page_config(page_title="Scanner", layout="wide")
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if BASE_DIR not in sys.path: sys.path.append(BASE_DIR)

# ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
LOGIC_PATH = os.path.join(BASE_DIR, "core", "logic.py")
RULES_PATH = os.path.join(BASE_DIR, "config", "default_rules.json")
DB_PATH = os.path.join(BASE_DIR, "trading_journal.db")

if not os.path.exists(LOGIC_PATH) or not os.path.exists(RULES_PATH):
    st.error("System Error: Configuration files missing."); st.stop()
try: from core.logic import RuleEngine
except ImportError: st.error("System Error: Engine load failed."); st.stop()

# --- ãƒ—ãƒ­ä»•æ§˜: ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¯ãƒ©ã‚¹ (Lightweight) ---
class DataProvider:
    def __init__(self):
        # APIã‚­ãƒ¼å–å¾—
        self.api_key = os.getenv("ALPACA_API_KEY") or st.secrets.get("ALPACA_API_KEY")
        self.api_secret = os.getenv("ALPACA_SECRET_KEY") or st.secrets.get("ALPACA_SECRET_KEY")
        self.use_alpaca = bool(self.api_key and self.api_secret)
        self.source_name = "Alpaca (Official Data)" if self.use_alpaca else "Yahoo Finance (Backup)"

    def fetch(self, symbols):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        if self.use_alpaca:
            try:
                return self._fetch_alpaca_direct(symbols)
            except Exception as e:
                st.warning(f"Alpaca Connection Failed: {e}. Switching to Backup.")
                self.source_name = "Yahoo Finance (Backup)"
                return self._fetch_yahoo(symbols)
        else:
            return self._fetch_yahoo(symbols)

    def _fetch_alpaca_direct(self, symbols):
        """ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã‚ãšç›´æ¥APIã‚’å©ãï¼ˆé«˜é€Ÿãƒ»ã‚¨ãƒ©ãƒ¼ãªã—ï¼‰"""
        data_map = {}
        # Alpaca Data API v2 Endpoint
        url = "https://data.alpaca.markets/v2/stocks/bars"
        
        headers = {
            "APCA-API-KEY-ID": self.api_key,
            "APCA-API-SECRET-KEY": self.api_secret,
            "accept": "application/json"
        }
        
        # éå»ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“è¨­å®š
        end_dt = datetime.now()
        start_dt = end_dt - timedelta(days=300)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        params = {
            "symbols": ",".join(symbols),
            "timeframe": "1Day",
            "start": start_dt.strftime("%Y-%m-%d"),
            "end": end_dt.strftime("%Y-%m-%d"),
            "limit": 1000,
            "adjustment": "raw",
            "feed": "iex"  # ç„¡æ–™ãƒ—ãƒ©ãƒ³ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ‰
        }

        response = requests.get(url, headers=headers, params=params, timeout=10)
        
        if response.status_code != 200:
            raise Exception(f"API Error {response.status_code}: {response.text}")

        json_data = response.json()
        bars_data = json_data.get("bars", {})

        for sym, bars in bars_data.items():
            if not bars or len(bars) < 50: continue
            
            # DataFrameã«å¤‰æ›
            df = pd.DataFrame(bars)
            # ã‚«ãƒ©ãƒ åã‚’çµ±ä¸€ (Alpaca: c->Close, v->Volume)
            df = df.rename(columns={"c": "Close", "v": "Volume"})
            
            # æŒ‡æ¨™è¨ˆç®—
            close = float(df['Close'].iloc[-1])
            sma50 = ta.trend.SMAIndicator(df['Close'], window=50).sma_indicator().iloc[-1]
            rsi14 = ta.momentum.RSIIndicator(df['Close'], window=14).rsi().iloc[-1]
            vol = float(df['Volume'].iloc[-1])
            
            data_map[sym] = {
                "symbol": sym, "price": close, "close": close,
                "sma": sma50, "rsi": rsi14, "volume": vol,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }
        
        return data_map

    def _fetch_yahoo(self, symbols):
        data_map = {}
        tickers = " ".join(symbols)
        if not tickers: return {}
        try:
            df = yf.download(tickers, period="6mo", interval="1d", group_by='ticker', auto_adjust=True, progress=False)
        except: return {}

        for sym in symbols:
            try:
                sdf = df if len(symbols)==1 else df[sym]
                if sdf.empty or len(sdf)<50: continue
                
                close = float(sdf['Close'].iloc[-1])
                sma50 = ta.trend.SMAIndicator(sdf['Close'], window=50).sma_indicator().iloc[-1]
                rsi14 = ta.momentum.RSIIndicator(sdf['Close'], window=14).rsi().iloc[-1]
                vol = float(sdf['Volume'].iloc[-1])
                
                data_map[sym] = {
                    "symbol": sym, "price": close, "close": close,
                    "sma": sma50, "rsi": rsi14, "volume": vol,
                    "timestamp": datetime.now().strftime("%H:%M:%S")
                }
            except: continue
        return data_map

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
def main():
    if not st.session_state.get("tos_agreed", False):
        st.warning("âš ï¸ ãƒ›ãƒ¼ãƒ ç”»é¢ã«æˆ»ã‚Šã€åˆ©ç”¨è¦ç´„ã«åŒæ„ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.title("ğŸ“¡ å¸‚å ´ã‚¹ã‚­ãƒ£ãƒŠãƒ¼")

    # DBæ¥ç¶š
    conn = sqlite3.connect(DB_PATH)
    try:
        w_df = pd.read_sql("SELECT * FROM watchlists LIMIT 1", conn)
        conn.close()
        if w_df.empty: st.warning("ç›£è¦–ãƒªã‚¹ãƒˆãŒç©ºã§ã™"); return
        targets = w_df.iloc[0]['symbols'].split(',')
    except: st.error("System Error: DB Connection Failed"); return

    # ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
    with open(RULES_PATH, "r", encoding='utf-8') as f:
        rule_set = json.load(f)

    # å‹•çš„ãƒ«ãƒ¼ãƒ«èª¬æ˜
    rule_descs = []
    for c in rule_set["conditions"]:
        target_val = c["right"].get("value", "æŒ‡æ¨™å€¤")
        op_map = {">": "ã‚ˆã‚Šä¸Š", "<": "ã‚ˆã‚Šä¸‹"}
        op_txt = op_map.get(c["operator"], c["operator"])
        rule_descs.append(f"- **{c['name']}**: {target_val} {op_txt}")

    with st.expander("âš™ï¸ é©ç”¨ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼è©³ç´°", expanded=False):
        c1, c2 = st.columns([1, 2])
        with c1:
            st.markdown(f"**ç›£è¦–å¯¾è±¡:** `{w_df.iloc[0]['name']}`")
            st.code(", ".join(targets))
        with c2:
            st.markdown(f"**ãƒ­ã‚¸ãƒƒã‚¯å:** `{rule_set['name']}`")
            st.markdown("\n".join(rule_descs))

    if st.button("ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ (Start Scan)", type="primary"):
        st.divider()
        provider = DataProvider()
        engine = RuleEngine()
        results = []
        
        with st.spinner(f"ãƒ‡ãƒ¼ã‚¿æ¥ç¶šä¸­... Source: {provider.source_name}"):
            m_data = provider.fetch(targets)
        
        if not m_data:
            st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¸‚å ´ãŒé–‰ã˜ã¦ã„ã‚‹ã‹ã€æ¥ç¶šã‚¨ãƒ©ãƒ¼ã§ã™ã€‚")
            return

        st.caption(f"â„¹ï¸ Data Source: {provider.source_name} | Fetched at: {datetime.now().strftime('%H:%M:%S')}")

        prog = st.progress(0)
        for i, sym in enumerate(targets):
            prog.progress((i+1)/len(targets))
            if sym not in m_data: continue
            
            data = m_data[sym]
            is_match, details = engine.evaluate(rule_set, data)
            
            reason = ""
            if not is_match:
                for _, res in details.items():
                    if not res['result'] and 'error' not in res:
                        reason = f"âŒ {res['name']} ({res['left_val']:.2f} / {res['right_val']:.2f}) [ã‚ã¨ {res['diff']:.2f}]"
                        break
                    elif 'error' in res:
                        reason = f"âš ï¸ Err: {res['error']}"
                        break

            results.append({
                "Symbol": sym,
                "Signal": "ğŸŸ¢ ENTRY" if is_match else "WAIT",
                "Price": f"${data['price']:.2f}",
                "RSI": f"{data['rsi']:.1f}",
                "Note": reason,
                "Details": details
            })
        time.sleep(0.2); prog.empty()

        df_r = pd.DataFrame(results)
        candidates = df_r[df_r["Signal"] == "ğŸŸ¢ ENTRY"]
        unmatched = df_r[df_r["Signal"] != "ğŸŸ¢ ENTRY"]

        if not candidates.empty:
            st.success(f"æ¤œå‡ºå®Œäº†: {len(candidates)} éŠ˜æŸ„ãŒæ¡ä»¶ã«åˆè‡´ã—ã¾ã™")
            for _, r in candidates.iterrows():
                with st.container(border=True):
                    c1, c2 = st.columns([1, 3])
                    c1.metric(r["Symbol"], r["Price"])
                    c2.markdown(f"### ğŸš€ Signal Confirmed\n**RSI:** {r['RSI']} | å…¨æ¡ä»¶ã‚¯ãƒªã‚¢")
        else:
            st.info("ç¾åœ¨ã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¡ä»¶ã‚’æº€ãŸã™éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        if not unmatched.empty:
            st.markdown("#### ç›£è¦–ç¶™ç¶šãƒªã‚¹ãƒˆ")
            st.dataframe(
                unmatched[["Symbol", "Price", "RSI", "Note"]],
                column_config={"Note": st.column_config.TextColumn("çŠ¶æ³ / ä¹–é›¢", width="large")},
                hide_index=True, use_container_width=True
            )

if __name__ == "__main__": main()
