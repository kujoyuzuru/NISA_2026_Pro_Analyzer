import streamlit as st
import pandas as pd
import yfinance as yf
import requests  # æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ç›´æ¥é€šä¿¡
import json
import os
import sqlite3
import ta
import time
import sys
from datetime import datetime, timedelta

# --- ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
st.set_page_config(page_title="Scanner", layout="wide")
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if BASE_DIR not in sys.path: sys.path.append(BASE_DIR)

# ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
LOGIC_PATH = os.path.join(BASE_DIR, "core", "logic.py")
RULES_PATH = os.path.join(BASE_DIR, "config", "default_rules.json")
DB_PATH = os.path.join(BASE_DIR, "trading_journal.db")

if not os.path.exists(LOGIC_PATH) or not os.path.exists(RULES_PATH):
    st.error("System Error: Config files missing."); st.stop()
try: from core.logic import RuleEngine
except ImportError: st.error("System Error: Logic engine failed."); st.stop()

# --- â˜…å¾©æ´»ï¼šDBè‡ªå‹•ä¿®å¾©æ©Ÿèƒ½ (Safety Net) ---
def force_init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS watchlists (
        id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, symbols TEXT)''')
    # ãƒ‡ãƒ¼ã‚¿ãŒãªã‘ã‚Œã°åˆæœŸå€¤ã‚’æŠ•å…¥
    c.execute("SELECT count(*) FROM watchlists")
    if c.fetchone()[0] == 0:
        c.execute("INSERT INTO watchlists (name, symbols) VALUES (?, ?)", 
                  ("Default Watchlist", "AAPL,MSFT,TSLA,NVDA,GOOGL,AMZN,META,AMD"))
    conn.commit()
    conn.close()

def get_db_connection():
    conn = sqlite3.connect(DB_PATH)
    try:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
        conn.execute("SELECT * FROM watchlists LIMIT 1")
    except sqlite3.OperationalError:
        conn.close()
        # ãªã‘ã‚Œã°ä¿®å¾©å®Ÿè¡Œ
        force_init_db()
        conn = sqlite3.connect(DB_PATH)
    return conn

# --- ãƒ—ãƒ­ä»•æ§˜: ãƒ‡ãƒ¼ã‚¿å–å¾— (Lightweight/No-Lib) ---
class DataProvider:
    def __init__(self):
        self.api_key = os.getenv("ALPACA_API_KEY") or st.secrets.get("ALPACA_API_KEY")
        self.api_secret = os.getenv("ALPACA_SECRET_KEY") or st.secrets.get("ALPACA_SECRET_KEY")
        self.use_alpaca = bool(self.api_key and self.api_secret)
        self.source_name = "Alpaca (Official)" if self.use_alpaca else "Yahoo Finance (Backup)"

    def fetch(self, symbols):
        if self.use_alpaca:
            try:
                return self._fetch_alpaca_direct(symbols)
            except Exception as e:
                st.warning(f"Alpaca Error: {e}. Switching to Backup.")
                self.source_name = "Yahoo Finance (Backup)"
                return self._fetch_yahoo(symbols)
        else:
            return self._fetch_yahoo(symbols)

    def _fetch_alpaca_direct(self, symbols):
        # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã‚ãšrequestsã§ç›´æ¥å©ãï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
        url = "https://data.alpaca.markets/v2/stocks/bars"
        headers = {
            "APCA-API-KEY-ID": self.api_key,
            "APCA-API-SECRET-KEY": self.api_secret,
            "accept": "application/json"
        }
        params = {
            "symbols": ",".join(symbols),
            "timeframe": "1Day",
            "limit": 300,
            "feed": "iex"
        }
        # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
        try:
            response = requests.get(url, headers=headers, params=params, timeout=5)
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            raise Exception(f"Connection failed: {e}")

        data_map = {}
        bars_data = response.json().get("bars", {})

        for sym, bars in bars_data.items():
            if not bars or len(bars) < 50: continue
            df = pd.DataFrame(bars)
            df = df.rename(columns={"c": "Close", "v": "Volume"})
            
            close = float(df['Close'].iloc[-1])
            sma50 = ta.trend.SMAIndicator(df['Close'], window=50).sma_indicator().iloc[-1]
            rsi14 = ta.momentum.RSIIndicator(df['Close'], window=14).rsi().iloc[-1]
            vol = float(df['Volume'].iloc[-1])
            
            data_map[sym] = {
                "symbol": sym, "price": close, "close": close,
                "sma": sma50, "rsi": rsi14, "volume": vol,
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }
        return data_map

    def _fetch_yahoo(self, symbols):
        data_map = {}
        tickers = " ".join(symbols)
        if not tickers: return {}
        try:
            df = yf.download(tickers, period="6mo", interval="1d", group_by='ticker', auto_adjust=True, progress=False)
        except: return {}

        for sym in symbols:
            try:
                sdf = df if len(symbols)==1 else df[sym]
                if sdf.empty or len(sdf)<50: continue
                close = float(sdf['Close'].iloc[-1])
                sma50 = ta.trend.SMAIndicator(sdf['Close'], window=50).sma_indicator().iloc[-1]
                rsi14 = ta.momentum.RSIIndicator(sdf['Close'], window=14).rsi().iloc[-1]
                vol = float(sdf['Volume'].iloc[-1])
                data_map[sym] = {
                    "symbol": sym, "price": close, "close": close,
                    "sma": sma50, "rsi": rsi14, "volume": vol,
                    "timestamp": datetime.now().strftime("%H:%M:%S")
                }
            except: continue
        return data_map

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
def main():
    if not st.session_state.get("tos_agreed", False):
        st.warning("âš ï¸ ãƒ›ãƒ¼ãƒ ç”»é¢ã«æˆ»ã‚Šã€åˆ©ç”¨è¦ç´„ã«åŒæ„ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.title("ğŸ“¡ å¸‚å ´ã‚¹ã‚­ãƒ£ãƒŠãƒ¼")

    # DBæ¥ç¶šï¼ˆä¿®å¾©æ©Ÿèƒ½ä»˜ãï¼‰
    try:
        conn = get_db_connection()
        w_df = pd.read_sql("SELECT * FROM watchlists LIMIT 1", conn)
        conn.close()
        if w_df.empty: st.warning("ç›£è¦–ãƒªã‚¹ãƒˆãŒç©ºã§ã™"); return
        targets = w_df.iloc[0]['symbols'].split(',')
    except Exception as e:
        # å…·ä½“çš„ãªã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤ºã—ã¦ãƒ‡ãƒãƒƒã‚°ã—ã‚„ã™ãã™ã‚‹
        st.error(f"Critical DB Error: {e}")
        if st.button("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å¼·åˆ¶ãƒªã‚»ãƒƒãƒˆ"):
            force_init_db()
            st.rerun()
        return

    # ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
    with open(RULES_PATH, "r", encoding='utf-8') as f:
        rule_set = json.load(f)

    # å‹•çš„ãƒ«ãƒ¼ãƒ«èª¬æ˜
    rule_descs = []
    for c in rule_set["conditions"]:
        target_val = c["right"].get("value", "æŒ‡æ¨™å€¤")
        op_map = {">": "ã‚ˆã‚Šä¸Š", "<": "ã‚ˆã‚Šä¸‹"}
        op_txt = op_map.get(c["operator"], c["operator"])
        rule_descs.append(f"- **{c['name']}**: {target_val} {op_txt}")

    with st.expander("âš™ï¸ é©ç”¨ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼è©³ç´°", expanded=False):
        c1, c2 = st.columns([1, 2])
        with c1:
            st.markdown(f"**ç›£è¦–å¯¾è±¡:** `{w_df.iloc[0]['name']}`")
            st.code(", ".join(targets))
        with c2:
            st.markdown(f"**ãƒ­ã‚¸ãƒƒã‚¯å:** `{rule_set['name']}`")
            st.markdown("\n".join(rule_descs))

    if st.button("ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ (Start Scan)", type="primary"):
        st.divider()
        provider = DataProvider()
        engine = RuleEngine()
        results = []
        
        with st.spinner(f"ãƒ‡ãƒ¼ã‚¿æ¥ç¶šä¸­... Source: {provider.source_name}"):
            m_data = provider.fetch(targets)
        
        if not m_data:
            st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ã€‚å¸‚å ´ãŒé–‰ã˜ã¦ã„ã‚‹ã‹ã€Yahoo/Alpacaä¸¡æ–¹ãŒå¿œç­”ã—ã¾ã›ã‚“ã€‚")
            return

        st.caption(f"â„¹ï¸ Data Source: {provider.source_name} | Fetched at: {datetime.now().strftime('%H:%M:%S')}")

        prog = st.progress(0)
        for i, sym in enumerate(targets):
            prog.progress((i+1)/len(targets))
            if sym not in m_data: continue
            
            data = m_data[sym]
            is_match, details = engine.evaluate(rule_set, data)
            
            reason = ""
            if not is_match:
                for _, res in details.items():
                    if not res['result'] and 'error' not in res:
                        reason = f"âŒ {res['name']} ({res['left_val']:.2f} / {res['right_val']:.2f}) [ã‚ã¨ {res['diff']:.2f}]"
                        break
                    elif 'error' in res:
                        reason = f"âš ï¸ Err: {res['error']}"
                        break

            results.append({
                "Symbol": sym,
                "Signal": "ğŸŸ¢ ENTRY" if is_match else "WAIT",
                "Price": f"${data['price']:.2f}",
                "RSI": f"{data['rsi']:.1f}",
                "Note": reason,
                "Details": details
            })
        time.sleep(0.2); prog.empty()

        df_r = pd.DataFrame(results)
        candidates = df_r[df_r["Signal"] == "ğŸŸ¢ ENTRY"]
        unmatched = df_r[df_r["Signal"] != "ğŸŸ¢ ENTRY"]

        if not candidates.empty:
            st.success(f"æ¤œå‡ºå®Œäº†: {len(candidates)} éŠ˜æŸ„ãŒåˆè‡´")
            for _, r in candidates.iterrows():
                with st.container(border=True):
                    c1, c2 = st.columns([1, 3])
                    c1.metric(r["Symbol"], r["Price"])
                    c2.markdown(f"### ğŸš€ Signal Confirmed\n**RSI:** {r['RSI']} | å…¨æ¡ä»¶ã‚¯ãƒªã‚¢")
        else:
            st.info("æ¡ä»¶ã‚’æº€ãŸã™éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        if not unmatched.empty:
            st.markdown("#### ç›£è¦–ç¶™ç¶šãƒªã‚¹ãƒˆ")
            st.dataframe(
                unmatched[["Symbol", "Price", "RSI", "Note"]],
                column_config={"Note": st.column_config.TextColumn("çŠ¶æ³ / ä¹–é›¢", width="large")},
                hide_index=True, use_container_width=True
            )

if __name__ == "__main__": main()
