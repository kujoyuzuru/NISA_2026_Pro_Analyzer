import streamlit as st
import pandas as pd
import yfinance as yf
import json
import os
import sqlite3
import ta
import time
import sys
from datetime import datetime

# ---------------------------------------------------------
# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— & ãƒ‘ã‚¹è§£æ±ºï¼ˆè¿·å­é˜²æ­¢ï¼‰
# ---------------------------------------------------------
st.set_page_config(page_title="Scanner v2", layout="wide")

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if BASE_DIR not in sys.path:
    sys.path.append(BASE_DIR)

# ãƒ‘ã‚¹å®šç¾©
LOGIC_PATH = os.path.join(BASE_DIR, "core", "logic.py")
RULES_PATH = os.path.join(BASE_DIR, "config", "default_rules.json")
DB_PATH = os.path.join(BASE_DIR, "trading_journal.db")

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
if not os.path.exists(LOGIC_PATH) or not os.path.exists(RULES_PATH):
    st.error("âš ï¸ å¿…è¦ãªã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# ã‚¨ãƒ³ã‚¸ãƒ³èª­ã¿è¾¼ã¿
try:
    from core.logic import RuleEngine
except ImportError:
    st.error("ãƒ­ã‚¸ãƒƒã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.stop()

# ---------------------------------------------------------
# å¼·åˆ¶DBä¿®å¾©æ©Ÿèƒ½
# ---------------------------------------------------------
def force_init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS watchlists (
        id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT, symbols TEXT)''')
    c.execute("SELECT count(*) FROM watchlists")
    if c.fetchone()[0] == 0:
        c.execute("INSERT INTO watchlists (name, symbols) VALUES (?, ?)", 
                  ("Default Watchlist", "AAPL,MSFT,TSLA,NVDA,GOOGL,AMZN,META,AMD"))
    conn.commit()
    conn.close()

# ---------------------------------------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ---------------------------------------------------------
def get_db_connection():
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute("SELECT * FROM watchlists LIMIT 1")
    except sqlite3.OperationalError:
        conn.close()
        force_init_db()
        conn = sqlite3.connect(DB_PATH)
    return conn

@st.cache_data(ttl=300) # 5åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆé®®åº¦é‡è¦–ï¼‰
def fetch_market_data(symbols):
    data_map = {}
    tickers = " ".join(symbols)
    if not tickers: return {}

    try:
        # éå»ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ—¥è¶³ï¼‰
        df = yf.download(tickers, period="6mo", interval="1d", group_by='ticker', auto_adjust=True, progress=False)
    except Exception:
        return {}

    for symbol in symbols:
        try:
            if len(symbols) == 1:
                stock_df = df
            else:
                if symbol not in df: continue
                stock_df = df[symbol]
            
            if stock_df.empty or len(stock_df) < 50: continue

            # æŒ‡æ¨™è¨ˆç®—
            close_price = float(stock_df['Close'].iloc[-1])
            sma_indicator = ta.trend.SMAIndicator(stock_df['Close'], window=50)
            sma_50 = sma_indicator.sma_indicator().iloc[-1]
            rsi_indicator = ta.momentum.RSIIndicator(stock_df['Close'], window=14)
            rsi_14 = rsi_indicator.rsi().iloc[-1]
            volume = float(stock_df['Volume'].iloc[-1])

            data_map[symbol] = {
                "symbol": symbol, "price": close_price, "close": close_price,
                "sma": sma_50, "rsi": rsi_14, "volume": volume,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        except Exception:
            continue
    return data_map

# ---------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³ç”»é¢å‡¦ç†
# ---------------------------------------------------------
def main():
    st.title("ğŸ“¡ Market Scanner v2.0")
    
    # â˜…é‡è¦ï¼šèª¤è§£é˜²æ­¢ã®å…è²¬è¡¨ç¤º
    st.warning("âš ï¸ **DEMO MODE:** è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ã¯é…å»¶ã¾ãŸã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å«ã¿ã¾ã™ã€‚å®Ÿå–å¼•ã«ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚")

    # DBæ¥ç¶š
    try:
        conn = get_db_connection()
        watchlist_df = pd.read_sql("SELECT * FROM watchlists LIMIT 1", conn)
        conn.close()
    except Exception as e:
        st.error(f"Database Error: {e}")
        if st.button("Fix Database"):
            force_init_db()
            st.rerun()
        return

    target_symbols = watchlist_df.iloc[0]['symbols'].split(',')

    # ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
    with open(RULES_PATH, "r", encoding='utf-8') as f:
        rule_set = json.load(f)

    # è¨­å®šè¡¨ç¤º
    with st.expander("âš™ï¸ Current Strategy & Target", expanded=True):
        c1, c2 = st.columns(2)
        with c1:
            st.markdown(f"**List:** `{watchlist_df.iloc[0]['name']}`")
            st.caption(", ".join(target_symbols))
        with c2:
            st.markdown(f"**Strategy:** `{rule_set['name']}`")
            st.markdown(f"_{rule_set['description']}_")

    # ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ
    if st.button("Run Scan", type="primary"):
        st.divider()
        engine = RuleEngine()
        results = []
        
        with st.spinner("Fetching market data..."):
            market_data_map = fetch_market_data(target_symbols)

        if not market_data_map:
            st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            return

        # â˜…é‡è¦ï¼šãƒ‡ãƒ¼ã‚¿æ™‚ç‚¹ã®æ˜ç¤º
        scan_time = datetime.now().strftime("%H:%M:%S")
        st.caption(f"ğŸ•’ Data fetched at: {scan_time} (JST)")

        progress_bar = st.progress(0)
        for i, symbol in enumerate(target_symbols):
            progress_bar.progress((i + 1) / len(target_symbols))
            
            if symbol not in market_data_map: continue

            data = market_data_map[symbol]
            is_match, details = engine.evaluate(rule_set, data)
            
            # ä¸ä¸€è‡´ç†ç”±ã®ç”Ÿæˆï¼ˆGPTæŒ‡æ‘˜ã¸ã®å¯¾å¿œï¼‰
            reject_reason = ""
            if not is_match:
                for code, res in details.items():
                    if not res['result']:
                        # å¤±æ•—ã—ãŸæ¡ä»¶ã‚’è¦‹ã¤ã‘ã¦ç†ç”±ã‚’æ›¸ã
                        val = res.get('left_val', 0)
                        threshold = res.get('right_val', 0)
                        op = res.get('operator', '')
                        reject_reason = f"âŒ {res['name']} NG ({val:.1f} {op} {threshold})"
                        break # æœ€åˆã®å¤±æ•—ç†ç”±ã ã‘æ¡ç”¨
            
            row = {
                "Symbol": symbol,
                "Status": "âœ… MATCH" if is_match else "Wait",
                "Price": f"${data['price']:.2f}",
                "RSI": f"{data['rsi']:.1f}",
                "Reason": reject_reason, # ç†ç”±ã‚«ãƒ©ãƒ 
                "Details": details
            }
            results.append(row)

        time.sleep(0.5)
        progress_bar.empty()

        # çµæœã®æŒ¯ã‚Šåˆ†ã‘
        df_results = pd.DataFrame(results)
        candidates = df_results[df_results["Status"] == "âœ… MATCH"]
        unmatched = df_results[df_results["Status"] != "âœ… MATCH"]

        # 1. å€™è£œãƒªã‚¹ãƒˆ
        st.subheader(f"Candidates ({len(candidates)})")
        if not candidates.empty:
            st.success("ã‚¨ãƒ³ãƒˆãƒªãƒ¼å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            for _, row in candidates.iterrows():
                with st.container(border=True):
                    c1, c2, c3 = st.columns([1, 1, 3])
                    c1.metric(row["Symbol"], row["Price"])
                    c2.metric("RSI", row["RSI"])
                    c3.success(f"**All Clear:** {rule_set['description']}")
        else:
            st.info("ç¾åœ¨ã€æ¡ä»¶ã«åˆè‡´ã™ã‚‹éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        # 2. ä¸ä¸€è‡´ãƒªã‚¹ãƒˆï¼ˆGPTæŒ‡æ‘˜ï¼šã“ã“ã‚’ãŸã ã®è¡¨ã«ã—ãªã„ï¼‰
        st.subheader("Watch List (Unmatched)")
        if not unmatched.empty:
            # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†
            display_df = unmatched[["Symbol", "Price", "RSI", "Reason"]]
            st.dataframe(
                display_df,
                column_config={
                    "Reason": st.column_config.TextColumn("Miss Reason", width="medium"),
                },
                hide_index=True,
                use_container_width=True
            )

if __name__ == "__main__":
    main()
