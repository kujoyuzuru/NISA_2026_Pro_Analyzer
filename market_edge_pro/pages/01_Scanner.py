import streamlit as st
import pandas as pd
import yfinance as yf
import json
import os
import sqlite3
import ta
import time
import sys

# ---------------------------------------------------------
# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— & ãƒ‘ã‚¹è§£æ±º
# ---------------------------------------------------------
st.set_page_config(page_title="Scanner", layout="wide")

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if BASE_DIR not in sys.path:
    sys.path.append(BASE_DIR)

# ãƒ‘ã‚¹ã®å®šç¾©
LOGIC_PATH = os.path.join(BASE_DIR, "core", "logic.py")
RULES_PATH = os.path.join(BASE_DIR, "config", "default_rules.json")
DB_PATH = os.path.join(BASE_DIR, "trading_journal.db")

# ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
if not os.path.exists(LOGIC_PATH):
    st.error(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {LOGIC_PATH}")
    st.stop()
if not os.path.exists(RULES_PATH):
    st.error(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {RULES_PATH}")
    st.stop()

# ãƒ­ã‚¸ãƒƒã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ã®èª­ã¿è¾¼ã¿
try:
    from core.logic import RuleEngine
except ImportError:
    st.error("ãƒ­ã‚¸ãƒƒã‚¯ã‚¨ãƒ³ã‚¸ãƒ³ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.stop()

# ---------------------------------------------------------
# â˜…ç·Šæ€¥ä¿®ç†æ©Ÿèƒ½ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–â˜…
# ---------------------------------------------------------
def force_init_db():
    """ãƒ†ãƒ¼ãƒ–ãƒ«ãŒãªã„å ´åˆã«ç„¡ç†ã‚„ã‚Šä½œæˆã™ã‚‹é–¢æ•°"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    # 1. ç›£è¦–ãƒªã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    c.execute('''
        CREATE TABLE IF NOT EXISTS watchlists (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            symbols TEXT NOT NULL
        )
    ''')
    
    # 2. ãƒ‡ãƒ¼ã‚¿ãŒç©ºãªã‚‰åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’å…¥ã‚Œã‚‹
    c.execute("SELECT count(*) FROM watchlists")
    if c.fetchone()[0] == 0:
        c.execute("INSERT INTO watchlists (name, symbols) VALUES (?, ?)", 
                  ("Default Watchlist", "AAPL,MSFT,TSLA,NVDA,GOOGL,AMZN,META,AMD"))

    # ãã®ä»–ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚‚å¿µã®ãŸã‚ä½œæˆ
    c.execute('''
        CREATE TABLE IF NOT EXISTS rule_sets (
            id TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            json_body TEXT NOT NULL
        )
    ''')
    c.execute('''
        CREATE TABLE IF NOT EXISTS scan_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            scanned_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            rule_set_id TEXT,
            symbol TEXT,
            is_match BOOLEAN,
            match_details JSON,
            market_data_snapshot JSON
        )
    ''')
    conn.commit()
    conn.close()

# ---------------------------------------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ---------------------------------------------------------
def get_db_connection():
    # æ¥ç¶šæ™‚ã«ãƒ†ãƒ¼ãƒ–ãƒ«ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ï¼ˆãªã‘ã‚Œã°ç›´ã™ï¼‰
    conn = sqlite3.connect(DB_PATH)
    try:
        conn.execute("SELECT * FROM watchlists LIMIT 1")
    except sqlite3.OperationalError:
        conn.close()
        # ã‚¨ãƒ©ãƒ¼ãŒå‡ºãŸã‚‰ä¿®ç†å®Ÿè¡Œ
        force_init_db()
        # å†æ¥ç¶š
        conn = sqlite3.connect(DB_PATH)
    return conn

@st.cache_data(ttl=3600)
def fetch_market_data(symbols):
    data_map = {}
    tickers = " ".join(symbols)
    if not tickers: return {}

    try:
        df = yf.download(tickers, period="6mo", interval="1d", group_by='ticker', auto_adjust=True, progress=False)
    except Exception:
        return {}

    for symbol in symbols:
        try:
            if len(symbols) == 1:
                stock_df = df
            else:
                if symbol not in df: continue
                stock_df = df[symbol]
            
            if stock_df.empty or len(stock_df) < 50: continue

            close_price = float(stock_df['Close'].iloc[-1])
            sma_indicator = ta.trend.SMAIndicator(stock_df['Close'], window=50)
            sma_50 = sma_indicator.sma_indicator().iloc[-1]
            rsi_indicator = ta.momentum.RSIIndicator(stock_df['Close'], window=14)
            rsi_14 = rsi_indicator.rsi().iloc[-1]
            volume = float(stock_df['Volume'].iloc[-1])

            data_map[symbol] = {
                "symbol": symbol, "price": close_price, "close": close_price,
                "sma": sma_50, "rsi": rsi_14, "volume": volume
            }
        except Exception:
            continue
    return data_map

# ---------------------------------------------------------
# ãƒ¡ã‚¤ãƒ³ç”»é¢å‡¦ç†
# ---------------------------------------------------------
def main():
    st.title("ğŸ“¡ Market Scanner")
    
    # DBæ¥ç¶š & ç›£è¦–ãƒªã‚¹ãƒˆå–å¾—
    try:
        conn = get_db_connection() # ã“ã“ã§è‡ªå‹•ä¿®å¾©ãŒèµ°ã‚‹
        watchlist_df = pd.read_sql("SELECT * FROM watchlists LIMIT 1", conn)
        conn.close()
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        if st.button("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å¼·åˆ¶ãƒªã‚»ãƒƒãƒˆã™ã‚‹"):
            force_init_db()
            st.rerun()
        return

    if watchlist_df.empty:
        st.warning("ç›£è¦–ãƒªã‚¹ãƒˆãŒç©ºã§ã™ã€‚")
        return

    target_symbols = watchlist_df.iloc[0]['symbols'].split(',')
    target_list_name = watchlist_df.iloc[0]['name']

    # ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
    with open(RULES_PATH, "r", encoding='utf-8') as f:
        rule_set = json.load(f)

    # è¨­å®šè¡¨ç¤º
    with st.expander("Scanner Settings", expanded=True):
        c1, c2 = st.columns(2)
        with c1:
            st.markdown(f"**Target List:** `{target_list_name}` ({len(target_symbols)} symbols)")
            st.caption(", ".join(target_symbols))
        with c2:
            st.markdown(f"**Strategy:** `{rule_set['name']}`")
            st.markdown(f"_{rule_set['description']}_")

    # ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ
    if st.button("Run Scan (Simulation)", type="primary"):
        st.divider()
        engine = RuleEngine()
        results = []

        with st.spinner(f"Scanning {len(target_symbols)} stocks..."):
            market_data_map = fetch_market_data(target_symbols)

        if not market_data_map:
            st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ã€ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã§ã™ã€‚")
            return

        progress_bar = st.progress(0)
        for i, symbol in enumerate(target_symbols):
            progress_bar.progress((i + 1) / len(target_symbols))
            
            if symbol not in market_data_map: continue

            data = market_data_map[symbol]
            is_match, details = engine.evaluate(rule_set, data)
            status_icon = "âœ… Candidate" if is_match else "unmatched"
            
            row = {
                "Symbol": symbol,
                "Status": status_icon,
                "Price": f"${data['price']:.2f}",
                "RSI": f"{data['rsi']:.1f}",
                "SMA50": f"${data['sma']:.2f}",
                "Details": details
            }
            results.append(row)

        time.sleep(0.5)
        progress_bar.empty()

        st.subheader("Scan Results")
        df_results = pd.DataFrame(results)
        
        candidates = df_results[df_results["Status"] == "âœ… Candidate"]
        if not candidates.empty:
            st.success(f"{len(candidates)} éŠ˜æŸ„ãŒæ¡ä»¶ä¸€è‡´ï¼")
            for _, row in candidates.iterrows():
                with st.container(border=True):
                    c1, c2, c3, c4 = st.columns([1, 1, 1, 3])
                    c1.metric("Symbol", row["Symbol"])
                    c1.write(f"**{row['Price']}**")
                    c2.metric("RSI(14)", row["RSI"])
                    c3.metric("SMA(50)", row["SMA50"])
                    
                    c4.write("ğŸ“‹ **Match Reason:**")
                    if isinstance(row["Details"], dict):
                        for code, res in row["Details"].items():
                            icon = "ğŸŸ¢" if res.get('result') else "ğŸ”´"
                            desc = res.get('desc', '')
                            val = res.get('left_val', 0)
                            c4.write(f"{icon} {desc} (Val: {val:.2f})")
        else:
            st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        with st.expander("See Unmatched Stocks"):
            st.dataframe(df_results.drop(columns=["Details"]))

if __name__ == "__main__":
    main()
