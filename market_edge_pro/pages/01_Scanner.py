import streamlit as st
import pandas as pd
import yfinance as yf
import alpaca_trade_api as tradeapi
import json
import os
import sqlite3
import ta
import time
import sys
from datetime import datetime, timedelta

# --- ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— ---
st.set_page_config(page_title="Scanner", layout="wide")
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if BASE_DIR not in sys.path: sys.path.append(BASE_DIR)

# ä¾å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
LOGIC_PATH = os.path.join(BASE_DIR, "core", "logic.py")
RULES_PATH = os.path.join(BASE_DIR, "config", "default_rules.json")
DB_PATH = os.path.join(BASE_DIR, "trading_journal.db")

if not os.path.exists(LOGIC_PATH) or not os.path.exists(RULES_PATH):
    st.error("System Error: Configuration files missing."); st.stop()
try: from core.logic import RuleEngine
except ImportError: st.error("System Error: Engine load failed."); st.stop()

# --- ãƒ—ãƒ­ä»•æ§˜: ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¯ãƒ©ã‚¹ ---
class DataProvider:
    def __init__(self):
        # Streamlit Secrets ã¾ãŸã¯ ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã‚­ãƒ¼ã‚’å–å¾—
        self.api_key = os.getenv("ALPACA_API_KEY") or st.secrets.get("ALPACA_API_KEY")
        self.api_secret = os.getenv("ALPACA_SECRET_KEY") or st.secrets.get("ALPACA_SECRET_KEY")
        self.use_alpaca = bool(self.api_key and self.api_secret)
        self.source_name = "Alpaca (IEX Real-time)" if self.use_alpaca else "Yahoo Finance (Delayed)"

    def fetch(self, symbols):
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—: Alpacaå„ªå…ˆ -> Yahooãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if self.use_alpaca:
            try:
                return self._fetch_alpaca(symbols)
            except Exception as e:
                st.warning(f"Alpaca API Error: {e}. Switching to Backup Source.")
                self.source_name = "Yahoo Finance (Backup)"
                return self._fetch_yahoo(symbols)
        else:
            return self._fetch_yahoo(symbols)

    def _fetch_alpaca(self, symbols):
        # Alpaca APIæ¥ç¶š
        api = tradeapi.REST(self.api_key, self.api_secret, base_url='https://paper-api.alpaca.markets', api_version='v2')
        data_map = {}
        
        # æ—¥è¶³å–å¾—ï¼ˆéå»200æ—¥åˆ†ã‚ã‚Œã°SMA50/200è¨ˆç®—å¯èƒ½ï¼‰
        # ç„¡æ–™ãƒ—ãƒ©ãƒ³ã®åˆ¶é™ã‚’è€ƒæ…®ã—ã€å°‘ã—ä½™è£•ã‚’æŒã¤
        end_dt = datetime.now() - timedelta(minutes=15) # 15åˆ†é…å»¶å¯¾ç­–
        start_dt = end_dt - timedelta(days=300)
        
        for sym in symbols:
            try:
                bars = api.get_bars(sym, tradeapi.TimeFrame.Day, start=start_dt.isoformat(), end=end_dt.isoformat(), limit=200).df
                if bars.empty or len(bars) < 50: continue
                
                # æŒ‡æ¨™è¨ˆç®—
                close = float(bars['close'].iloc[-1])
                sma50 = ta.trend.SMAIndicator(bars['close'], window=50).sma_indicator().iloc[-1]
                rsi14 = ta.momentum.RSIIndicator(bars['close'], window=14).rsi().iloc[-1]
                vol = float(bars['volume'].iloc[-1])
                
                data_map[sym] = {
                    "symbol": sym, "price": close, "close": close,
                    "sma": sma50, "rsi": rsi14, "volume": vol,
                    "timestamp": datetime.now().strftime("%H:%M:%S")
                }
            except: continue
        return data_map

    def _fetch_yahoo(self, symbols):
        data_map = {}
        tickers = " ".join(symbols)
        if not tickers: return {}
        try:
            df = yf.download(tickers, period="6mo", interval="1d", group_by='ticker', auto_adjust=True, progress=False)
        except: return {}

        for sym in symbols:
            try:
                sdf = df if len(symbols)==1 else df[sym]
                if sdf.empty or len(sdf)<50: continue
                
                close = float(sdf['Close'].iloc[-1])
                sma50 = ta.trend.SMAIndicator(sdf['Close'], window=50).sma_indicator().iloc[-1]
                rsi14 = ta.momentum.RSIIndicator(sdf['Close'], window=14).rsi().iloc[-1]
                vol = float(sdf['Volume'].iloc[-1])
                
                data_map[sym] = {
                    "symbol": sym, "price": close, "close": close,
                    "sma": sma50, "rsi": rsi14, "volume": vol,
                    "timestamp": datetime.now().strftime("%H:%M:%S")
                }
            except: continue
        return data_map

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
def main():
    # åŒæ„ãƒã‚§ãƒƒã‚¯ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å…±æœ‰ï¼‰
    if not st.session_state.get("tos_agreed", False):
        st.warning("âš ï¸ ãƒ›ãƒ¼ãƒ ç”»é¢ã«æˆ»ã‚Šã€åˆ©ç”¨è¦ç´„ã«åŒæ„ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.title("ğŸ“¡ å¸‚å ´ã‚¹ã‚­ãƒ£ãƒŠãƒ¼")

    # DBæ¥ç¶š
    conn = sqlite3.connect(DB_PATH)
    try:
        w_df = pd.read_sql("SELECT * FROM watchlists LIMIT 1", conn)
        conn.close()
        if w_df.empty: st.warning("ç›£è¦–ãƒªã‚¹ãƒˆãŒç©ºã§ã™"); return
        targets = w_df.iloc[0]['symbols'].split(',')
    except: st.error("System Error: DB Connection failed."); return

    # ãƒ«ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
    with open(RULES_PATH, "r", encoding='utf-8') as f:
        rule_set = json.load(f)

    # å‹•çš„ãƒ«ãƒ¼ãƒ«èª¬æ˜
    rule_descs = []
    for c in rule_set["conditions"]:
        target_val = c["right"].get("value", "æŒ‡æ¨™å€¤")
        op_map = {">": "ã‚ˆã‚Šä¸Š", "<": "ã‚ˆã‚Šä¸‹"}
        op_txt = op_map.get(c["operator"], c["operator"])
        rule_descs.append(f"- **{c['name']}**: {target_val} {op_txt}")

    # UI: è¨­å®šãƒ‘ãƒãƒ«ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
    with st.expander("âš™ï¸ é©ç”¨ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼è©³ç´°", expanded=False): # æœ¬ç•ªãªã®ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯é–‰ã˜ã‚‹
        c1, c2 = st.columns([1, 2])
        with c1:
            st.markdown(f"**ç›£è¦–å¯¾è±¡:** `{w_df.iloc[0]['name']}`")
            st.code(", ".join(targets))
        with c2:
            st.markdown(f"**ãƒ­ã‚¸ãƒƒã‚¯å:** `{rule_set['name']}`")
            st.markdown("\n".join(rule_descs))

    # ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ
    if st.button("ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ (Start Scan)", type="primary"):
        st.divider()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–
        provider = DataProvider()
        engine = RuleEngine()
        results = []
        
        with st.spinner(f"ãƒ‡ãƒ¼ã‚¿æ¥ç¶šä¸­... Source: {provider.source_name}"):
            m_data = provider.fetch(targets)
        
        if not m_data:
            st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¸‚å ´ãŒé–‰ã˜ã¦ã„ã‚‹ã‹ã€æ¥ç¶šã‚¨ãƒ©ãƒ¼ã§ã™ã€‚")
            return

        # ã‚½ãƒ¼ã‚¹ã®æ˜ç¤ºï¼ˆä¿¡é ¼æ€§æ‹…ä¿ï¼‰
        st.caption(f"â„¹ï¸ Data Source: {provider.source_name} | Fetched at: {datetime.now().strftime('%H:%M:%S')}")

        prog = st.progress(0)
        for i, sym in enumerate(targets):
            prog.progress((i+1)/len(targets))
            if sym not in m_data: continue
            
            data = m_data[sym]
            is_match, details = engine.evaluate(rule_set, data)
            
            reason = ""
            if not is_match:
                for _, res in details.items():
                    if not res['result'] and 'error' not in res:
                        reason = f"âŒ {res['name']} ({res['left_val']:.2f} / {res['right_val']:.2f}) [ã‚ã¨ {res['diff']:.2f}]"
                        break
                    elif 'error' in res:
                        reason = f"âš ï¸ Err: {res['error']}"
                        break

            results.append({
                "Symbol": sym,
                "Signal": "ğŸŸ¢ ENTRY" if is_match else "WAIT", # ã‚ˆã‚Šå®Ÿæˆ¦çš„ãªè¡¨ç¾ã¸
                "Price": f"${data['price']:.2f}",
                "RSI": f"{data['rsi']:.1f}",
                "Note": reason,
                "Details": details
            })
        time.sleep(0.2); prog.empty()

        # çµæœè¡¨ç¤º
        df_r = pd.DataFrame(results)
        candidates = df_r[df_r["Signal"] == "ğŸŸ¢ ENTRY"]
        unmatched = df_r[df_r["Signal"] != "ğŸŸ¢ ENTRY"]

        if not candidates.empty:
            st.success(f"æ¤œå‡ºå®Œäº†: {len(candidates)} éŠ˜æŸ„ãŒæ¡ä»¶ã«åˆè‡´ã—ã¾ã™")
            for _, r in candidates.iterrows():
                with st.container(border=True):
                    c1, c2 = st.columns([1, 3])
                    c1.metric(r["Symbol"], r["Price"])
                    c2.markdown(f"### ğŸš€ Signal Confirmed\n**RSI:** {r['RSI']} | å…¨æ¡ä»¶ã‚¯ãƒªã‚¢")
        else:
            st.info("ç¾åœ¨ã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¡ä»¶ã‚’æº€ãŸã™éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

        if not unmatched.empty:
            st.markdown("#### ç›£è¦–ç¶™ç¶šãƒªã‚¹ãƒˆ")
            st.dataframe(
                unmatched[["Symbol", "Price", "RSI", "Note"]],
                column_config={"Note": st.column_config.TextColumn("çŠ¶æ³ / ä¹–é›¢", width="large")},
                hide_index=True, use_container_width=True
            )

if __name__ == "__main__": main()
