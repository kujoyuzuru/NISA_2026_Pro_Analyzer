import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timedelta
import uuid
import os

# --- 1. ã‚·ã‚¹ãƒ†ãƒ è¨­å®š (Systematic Rules) ---
st.set_page_config(page_title="Market Edge Pro - Systematic", page_icon="ðŸ¦…", layout="wide")

MODEL_VERSION = "v4.0_Auto_Balanced"
COST_MODEL = "0.5% (Round-Trip)" # å¾€å¾©ã‚³ã‚¹ãƒˆ
MAX_SECTOR_ALLOCATION = 2 # 1ã‚»ã‚¯ã‚¿ãƒ¼ã‚ãŸã‚Šã®æœ€å¤§éŠ˜æŸ„æ•°
PORTFOLIO_SIZE = 5
HISTORY_FILE = "master_execution_log.csv" # å…¨å±¥æ­´ä¿å­˜ç”¨

# --- 2. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»åˆ†æžãƒ­ã‚¸ãƒƒã‚¯ ---
@st.cache_data(ttl=3600)
def fetch_market_context():
    try:
        bench = yf.Ticker("QQQ")
        hist = bench.history(period="1d")
        if not hist.empty:
            return hist['Close'].iloc[-1]
        return 0.0
    except:
        return 0.0

@st.cache_data(ttl=3600)
def fetch_stock_data(tickers):
    data_list = []
    run_id = str(uuid.uuid4())[:8]
    cutoff_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    with st.status("ðŸ¦… åŽ³æ ¼ã‚¹ã‚­ãƒ£ãƒ³ & ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸å®šä¸­...", expanded=True) as status:
        total = len(tickers)
        for i, ticker in enumerate(tickers):
            status.update(label=f"Scanning... {ticker} ({i+1}/{total})")
            
            try:
                stock = yf.Ticker(ticker)
                try:
                    info = stock.info
                except:
                    continue 

                hist = stock.history(period="1y")
                if hist.empty: continue

                # --- A. Raw Data ---
                price = info.get('currentPrice', hist['Close'].iloc[-1])
                sector = info.get('sector', 'Unknown')
                
                # 1. Valuation
                official_peg = info.get('pegRatio')
                fwd_pe = info.get('forwardPE')
                growth = info.get('earningsGrowth')
                
                peg_val = np.nan
                peg_type = "-" 
                
                if official_peg is not None:
                    peg_val = official_peg
                    peg_type = "Official"
                elif fwd_pe is not None and growth is not None and growth > 0:
                    peg_val = fwd_pe / (growth * 100)
                    peg_type = "Modified" # Modified PEG
                
                # 2. Consensus & Statistics
                target_mean = info.get('targetMeanPrice')
                target_high = info.get('targetHighPrice')
                target_low = info.get('targetLowPrice')
                analysts = info.get('numberOfAnalystOpinions', 0)
                
                upside_val = 0.0
                spread_val = 1.0
                
                if target_mean and target_mean > 0 and price > 0:
                    upside_val = (target_mean - price) / price
                    if target_high and target_low:
                        spread_val = (target_high - target_low) / target_mean
                
                # Confidence Factor (Sigmoid-like)
                # äººæ•°ãŒå¤šã„ã»ã©ä¿¡é ¼åº¦UP (15åã§MAX)
                conf_factor = min(1.0, analysts / 15.0) if analysts >= 3 else 0.0

                # 3. Trend
                sma50 = hist['Close'].rolling(window=50).mean().iloc[-1]
                sma200 = hist['Close'].rolling(window=200).mean().iloc[-1]

                # --- B. Scoring Logic ---
                score = 0
                breakdown = []

                # 1. Valuation (Official Only)
                if peg_type == "Official" and pd.notna(peg_val):
                    base_points = 0
                    if 0 < peg_val < 1.0: base_points = 30
                    elif peg_val < 1.5: base_points = 20
                    elif peg_val < 2.0: base_points = 10
                    score += base_points
                
                # 2. Trend
                trend_ok = False
                if price > sma50 > sma200:
                    score += 30
                    trend_ok = True
                
                # 3. Upside (Risk Adjusted)
                if upside_val > 0:
                    base_upside = 0
                    if upside_val > 0.2: base_upside = 20
                    elif upside_val > 0.1: base_upside = 10
                    
                    if base_upside > 0:
                        # Spreadå‰²å¼•ã¨äººæ•°ä¿¡é ¼åº¦ã®äºŒé‡ãƒ•ã‚£ãƒ«ã‚¿
                        spread_discount = max(0.0, 1.0 - spread_val)
                        final_factor = spread_discount * conf_factor
                        score += int(base_upside * final_factor)

                # 4. RSI
                delta = hist['Close'].diff()
                gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                rs = gain / loss
                rsi = 100 - (100 / (1 + rs)).iloc[-1]
                
                if 40 <= rsi <= 60 and trend_ok:
                    score += 20
                elif rsi > 75:
                    score -= 10

                # Grade
                grade = "C"
                if score >= 80: grade = "S"
                elif score >= 60: grade = "A"
                elif score >= 40: grade = "B"

                data_list.append({
                    "Run_ID": run_id,
                    "Scan_Time": cutoff_time,
                    "Ticker": ticker,
                    "Sector": sector,
                    "Score": int(score),
                    "Grade": grade,
                    "Price_At_Scan": price,
                    # --- Snapshot Data ---
                    "PEG_Val": peg_val,
                    "PEG_Type": peg_type,
                    "Spread": spread_val,
                    "Analysts": analysts,
                    "Upside": upside_val,
                    "RSI": rsi,
                    "Model_Ver": MODEL_VERSION
                })
            
            except Exception:
                continue
        
        status.update(label="âœ… Analysis Complete", state="complete", expanded=False)
    
    return pd.DataFrame(data_list)

# --- 3. ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  (å¼·åˆ¶åˆ†æ•£) ---
def build_portfolio(df):
    """
    ã‚¹ã‚³ã‚¢é †ã«é¸å®šã™ã‚‹ãŒã€åŒã‚»ã‚¯ã‚¿ãƒ¼ã¯æœ€å¤§2éŠ˜æŸ„ã¾ã§ã¨ã™ã‚‹ã€‚
    3éŠ˜æŸ„ç›®ä»¥é™ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã€æ¬¡ç‚¹ã®åˆ¥ã‚»ã‚¯ã‚¿ãƒ¼éŠ˜æŸ„ã‚’æŽ¡ç”¨ã™ã‚‹ã€‚
    """
    df_sorted = df.sort_values('Score', ascending=False)
    portfolio = []
    sector_counts = {}
    
    logs = []
    
    for _, row in df_sorted.iterrows():
        if len(portfolio) >= PORTFOLIO_SIZE:
            break
            
        sec = row['Sector']
        current_count = sector_counts.get(sec, 0)
        
        if current_count < MAX_SECTOR_ALLOCATION:
            portfolio.append(row)
            sector_counts[sec] = current_count + 1
        else:
            logs.append(f"âš ï¸ Skip {row['Ticker']} ({sec}): Sector Limit Reached")
            
    return pd.DataFrame(portfolio), logs

# --- 4. å±¥æ­´ä¿å­˜æ©Ÿèƒ½ ---
def save_to_history(df_portfolio):
    """å®Ÿè¡Œã•ã‚ŒãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ¡ˆã‚’å¼·åˆ¶çš„ã«è¿½è¨˜ä¿å­˜ã™ã‚‹"""
    # æ¤œè¨¼ç”¨ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ï¼ˆç©ºæ¬„ï¼‰
    df_portfolio["Cost_Model"] = COST_MODEL
    df_portfolio["Entry_Date_Est"] = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')
    df_portfolio["Exit_Date_Est"] = (datetime.now() + timedelta(days=30)).strftime('%Y-%m-%d')
    df_portfolio["Actual_Entry_Price"] = np.nan # å¾Œã§åŸ‹ã‚ã‚‹
    df_portfolio["Actual_Exit_Price"] = np.nan  # å¾Œã§åŸ‹ã‚ã‚‹
    df_portfolio["Benchmark_Entry"] = np.nan    # å¾Œã§åŸ‹ã‚ã‚‹
    df_portfolio["Benchmark_Exit"] = np.nan     # å¾Œã§åŸ‹ã‚ã‚‹
    
    # CSVã«è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ã§ä¿å­˜
    if not os.path.exists(HISTORY_FILE):
        df_portfolio.to_csv(HISTORY_FILE, index=False)
    else:
        df_portfolio.to_csv(HISTORY_FILE, mode='a', header=False, index=False)
    
    return df_portfolio

# --- 5. ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.title("ðŸ¦… Market Edge Pro (Systematic Trader)")
st.caption(f"Ver: {MODEL_VERSION} | Protocol: Auto-Sector-Cap (Max {MAX_SECTOR_ALLOCATION}) | Cost: {COST_MODEL}")

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
bench_price = fetch_market_context()
st.metric("Context: QQQ Current", f"${bench_price:.2f}")

with st.expander("ðŸ¤– System Logic (äººé–“ã«ã‚ˆã‚‹æ”¹å¤‰ä¸å¯)", expanded=True):
    st.markdown(f"""
    1.  **Auto Sector Cap:** 1ã¤ã®ã‚»ã‚¯ã‚¿ãƒ¼ã‹ã‚‰ã¯æœ€å¤§ **{MAX_SECTOR_ALLOCATION}éŠ˜æŸ„** ã—ã‹æŽ¡ç”¨ã—ã¾ã›ã‚“ã€‚3éŠ˜æŸ„ç›®ä»¥é™ã¯ã‚¹ã‚³ã‚¢ãŒé«˜ãã¦ã‚‚è‡ªå‹•çš„ã«å´ä¸‹ã•ã‚Œã¾ã™ã€‚
    2.  **Master Logging:** ã‚¹ã‚­ãƒ£ãƒ³çµæžœã¯è‡ªå‹•çš„ã«ã‚µãƒ¼ãƒãƒ¼(ãƒ­ãƒ¼ã‚«ãƒ«)ã® `master_execution_log.csv` ã«è¨˜éŒ²ã•ã‚Œã¾ã™ã€‚å¾Œå‡ºã—ã®é¸æŠžã¯ã§ãã¾ã›ã‚“ã€‚
    3.  **Strict Audit Schema:** å‡ºåŠ›ã•ã‚Œã‚‹CSVã«ã¯ã€æ¤œè¨¼ã«å¿…è¦ãªã€Œã‚³ã‚¹ãƒˆã€ã€ŒEntry/Exitæ—¥ã€ã€Œãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ä¾¡æ ¼è¨˜å…¥æ¬„ã€ãŒäºˆã‚ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚
    """)

TARGETS = ["NVDA", "MSFT", "AAPL", "AMZN", "GOOGL", "META", "TSLA", "AVGO", "AMD", "PLTR", "ARM", "SMCI", "COIN", "CRWD", "LLY", "NVO", "COST", "NFLX", "INTC"]

if st.button("RUN SYSTEM (Generate & Log)", type="primary"):
    # 1. å…¨éŠ˜æŸ„ã‚¹ã‚­ãƒ£ãƒ³
    raw_df = fetch_stock_data(TARGETS)
    
    if not raw_df.empty:
        # 2. ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰
        portfolio_df, logic_logs = build_portfolio(raw_df)
        
        # 3. å¼·åˆ¶ãƒ­ã‚°ä¿å­˜
        final_csv_df = save_to_history(portfolio_df)
        
        # --- UIè¡¨ç¤º ---
        st.subheader(f"ðŸ† Systematic Portfolio (Run ID: {portfolio_df['Run_ID'].iloc[0]})")
        
        # é™¤å¤–ãƒ­ã‚°ã®è¡¨ç¤º
        if logic_logs:
            for log in logic_logs:
                st.warning(log)
        else:
            st.success("âœ… No Sector Conflicts. Pure Score Selection.")
            
        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªè¡¨
        st.dataframe(
            portfolio_df[['Ticker', 'Sector', 'Score', 'PEG_Val', 'Spread', 'Price_At_Scan']]
            .style
            .format({'Price_At_Scan': '${:.2f}', 'Score': '{:.0f}', 'PEG_Val': '{:.2f}', 'Spread': '{:.1%}'})
            .background_gradient(subset=['Score'], cmap='Greens')
            .highlight_null(color='gray'),
            use_container_width=True
        )

        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (æ¤œè¨¼ç”¨ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆä»˜ã)
        csv = final_csv_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ðŸ“¥ Download Audit Plan (è¨˜å…¥ç”¨CSV)",
            data=csv,
            file_name=f'TradePlan_{datetime.now().strftime("%Y%m%d_%H%M")}.csv',
            mime='text/csv',
            help="ã“ã®CSVã«ã¯ã€Žå®Ÿéš›ã®Entryä¾¡æ ¼ã€ã€ŽBenchmarkä¾¡æ ¼ã€ã‚’è¨˜å…¥ã™ã‚‹ç©ºæ¬„ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"
        )

        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆç°¡æ˜“ï¼‰
        st.divider()
        st.write("ðŸ“œ Local Execution History (Last 10 entries)")
        if os.path.exists(HISTORY_FILE):
            history_df = pd.read_csv(HISTORY_FILE)
            st.dataframe(history_df.tail(10), use_container_width=True)
        else:
            st.caption("No history yet.")
            
    else:
        st.error("Data fetch failed.")
