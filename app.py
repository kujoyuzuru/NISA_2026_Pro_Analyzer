import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime, timedelta
import uuid
import os
import hashlib
from collections import Counter

# --- 1. ã‚·ã‚¹ãƒ†ãƒ è¨­å®š ---
st.set_page_config(page_title="Market Edge Pro - Blockchain Audit", page_icon="ğŸ¦…", layout="wide")

MODEL_VERSION = "v6.0_Chained_Protocol"
COST_MODEL = 0.005 # å¾€å¾©0.5%
MAX_SECTOR_ALLOCATION = 2
PORTFOLIO_SIZE = 5
HISTORY_FILE = "master_execution_log.csv"

# --- 2. ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³ãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---

def get_last_hash():
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€çµ‚è¡Œã®ãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—ã™ã‚‹ï¼ˆãƒã‚§ãƒ¼ãƒ³ç”¨ï¼‰"""
    if not os.path.exists(HISTORY_FILE):
        return "GENESIS_BLOCK_000000000000" # åˆæœŸãƒãƒƒã‚·ãƒ¥
    
    try:
        df = pd.read_csv(HISTORY_FILE)
        if df.empty:
            return "GENESIS_BLOCK_000000000000"
        # æœ€çµ‚è¡Œã®ãƒãƒƒã‚·ãƒ¥åˆ—ã‚’å–å¾—
        return df.iloc[-1]['Record_Hash']
    except:
        return "BROKEN_CHAIN_ERROR"

def calculate_chain_hash(prev_hash, content_string):
    """å‰ã®ãƒãƒƒã‚·ãƒ¥ + å†…å®¹ ã§æ–°ã—ã„ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ (Chained Hashing)"""
    combined = f"{prev_hash}|{content_string}"
    return hashlib.sha256(combined.encode()).hexdigest()

def decay_function(spread_val):
    """Spreadã«å¯¾ã™ã‚‹é€£ç¶šçš„ãªå‰²å¼•é–¢æ•°: 1 / (1 + Spread)"""
    return 1.0 / (1.0 + spread_val)

@st.cache_data(ttl=3600)
def fetch_market_context():
    try:
        bench = yf.Ticker("QQQ")
        hist = bench.history(period="1d")
        if not hist.empty:
            return hist['Close'].iloc[-1]
        return 0.0
    except:
        return 0.0

@st.cache_data(ttl=3600)
def fetch_stock_data(tickers):
    data_list = []
    run_id = str(uuid.uuid4())[:8]
    # æ™‚åˆ»ã‚’ç§’ã¾ã§è¨˜éŒ²
    fetch_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    with st.status("ğŸ¦… ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ãƒã‚§ãƒ¼ãƒ³è¨˜éŒ²æº–å‚™ä¸­...", expanded=True) as status:
        total = len(tickers)
        for i, ticker in enumerate(tickers):
            status.update(label=f"Scanning... {ticker} ({i+1}/{total})")
            
            try:
                stock = yf.Ticker(ticker)
                try:
                    info = stock.info
                except:
                    continue 

                hist = stock.history(period="5d") # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿
                if hist.empty: continue

                # --- A. Data Snapshot ---
                # æœ€æ–°ã®ç¢ºå®šå€¤ï¼ˆå ´ä¸­ãªã‚‰ç¾åœ¨å€¤ã€é–‰å ´å¾Œãªã‚‰çµ‚å€¤ï¼‰
                price = info.get('currentPrice', hist['Close'].iloc[-1])
                sector = info.get('sector', 'Unknown')
                
                # 1. Valuation
                official_peg = info.get('pegRatio')
                fwd_pe = info.get('forwardPE')
                growth = info.get('earningsGrowth')
                
                peg_val = np.nan
                peg_type = "-" 
                
                if official_peg is not None:
                    peg_val = official_peg
                    peg_type = "Official"
                elif fwd_pe is not None and growth is not None and growth > 0:
                    peg_val = fwd_pe / (growth * 100)
                    peg_type = "Modified"
                
                # 2. Consensus
                target_mean = info.get('targetMeanPrice')
                target_high = info.get('targetHighPrice')
                target_low = info.get('targetLowPrice')
                analysts = info.get('numberOfAnalystOpinions', 0)
                
                upside_val = 0.0
                spread_val = 0.5
                
                if target_mean and target_mean > 0 and price > 0:
                    upside_val = (target_mean - price) / price
                    if target_high and target_low:
                        spread_val = (target_high - target_low) / target_mean
                
                # Confidence
                conf_factor = min(1.0, analysts / 15.0) if analysts >= 3 else 0.0

                # 3. Trend
                sma50 = hist['Close'].rolling(window=50).mean().iloc[-1] if len(hist) >= 50 else price
                sma200 = hist['Close'].rolling(window=200).mean().iloc[-1] if len(hist) >= 200 else price
                
                # --- B. Scoring ---
                score = 0
                
                # 1. Valuation
                if peg_type == "Official" and pd.notna(peg_val):
                    base_points = 0
                    if 0 < peg_val < 1.0: base_points = 30
                    elif peg_val < 1.5: base_points = 20
                    elif peg_val < 2.0: base_points = 10
                    score += base_points
                
                # 2. Trend (Simplified for speed)
                trend_ok = False
                # ãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã¯ç¾åœ¨ã®ä¾¡æ ¼ã ã‘ã§åˆ¤å®šã—ãªã„ã‚ˆã†ã‚¬ãƒ¼ãƒ‰
                if len(hist) >= 200 and price > sma50 > sma200:
                    score += 30
                    trend_ok = True
                
                # 3. Upside (Decay)
                if upside_val > 0:
                    base_upside = 0
                    if upside_val > 0.2: base_upside = 20
                    elif upside_val > 0.1: base_upside = 10
                    
                    if base_upside > 0:
                        spread_discount = decay_function(spread_val)
                        final_factor = spread_discount * conf_factor
                        score += int(base_upside * final_factor)

                # 4. RSI
                # (ç›´è¿‘14æ—¥è¨ˆç®—ã¯çœç•¥ã›ãšè¡Œã†ã¹ãã ãŒã€ã‚³ãƒ¼ãƒ‰é•·å‰Šæ¸›ã®ãŸã‚ç°¡æ˜“å®Ÿè£…)
                rsi = 50 

                grade = "C"
                if score >= 80: grade = "S"
                elif score >= 60: grade = "A"
                elif score >= 40: grade = "B"

                data_list.append({
                    "Run_ID": run_id,
                    "Scan_Time": fetch_time,
                    "Ticker": ticker,
                    "Sector": sector,
                    "Score": int(score),
                    "Price_At_Scan": price,
                    "PEG_Val": peg_val,
                    "Spread": spread_val,
                    "Upside": upside_val
                })
            
            except Exception:
                continue
        
        status.update(label="âœ… Scan Complete", state="complete", expanded=False)
    
    return pd.DataFrame(data_list)

# --- 3. ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹ç¯‰ ---
def build_portfolio(df):
    df_sorted = df.sort_values('Score', ascending=False)
    portfolio = []
    sector_counts = {}
    logs = []
    
    for _, row in df_sorted.iterrows():
        if len(portfolio) >= PORTFOLIO_SIZE: break
        sec = row['Sector']
        current_count = sector_counts.get(sec, 0)
        
        if current_count < MAX_SECTOR_ALLOCATION:
            portfolio.append(row)
            sector_counts[sec] = current_count + 1
        else:
            logs.append(f"Skip {row['Ticker']} ({sec}): Cap Reached")
            
    return pd.DataFrame(portfolio), logs

# --- 4. å±¥æ­´ä¿å­˜ (Chained Hashing) ---
def save_to_history(df_portfolio):
    """
    ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³ã®ã‚ˆã†ã«ã€å‰ã®è¡Œã®ãƒãƒƒã‚·ãƒ¥ã‚’ä½¿ã£ã¦æ–°ã—ã„ãƒãƒƒã‚·ãƒ¥ã‚’ä½œã‚‹ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€éå»ã®è¡Œã‚’æ”¹ã–ã‚“ã™ã‚‹ã¨é€£é–ãŒå£Šã‚Œã¦ãƒãƒ¬ã‚‹ã€‚
    """
    # æ—¢å­˜ã®æœ€çµ‚ãƒãƒƒã‚·ãƒ¥ã‚’å–å¾—
    prev_hash = get_last_hash()
    
    df_to_save = df_portfolio.copy()
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸
    df_to_save["Prev_Hash_Ref"] = prev_hash # å‰ã®ãƒ–ãƒ­ãƒƒã‚¯ã¸ã®ãƒªãƒ³ã‚¯
    df_to_save["Protocol_Entry"] = "Next_Open"
    df_to_save["Protocol_Exit"] = "Entry+20days_Open"
    
    # è¡Œã”ã¨ã®ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ï¼ˆç°¡æ˜“çš„ã«DataFrameå…¨ä½“ã‚’1ãƒ–ãƒ­ãƒƒã‚¯ã¨ã™ã‚‹ï¼‰
    # å®Ÿéš›ã¯è¡Œã”ã¨ã«ã‚„ã‚‹ã®ãŒç†æƒ³ã ãŒã€ä»Šå›ã¯Runå˜ä½ã§ãƒ–ãƒ­ãƒƒã‚¯åŒ–
    content_str = df_to_save[['Run_ID', 'Ticker', 'Score', 'Scan_Time']].to_string()
    new_hash = calculate_chain_hash(prev_hash, content_str)
    
    df_to_save["Record_Hash"] = new_hash # ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã®ç½²å
    
    # ä¿å­˜
    if not os.path.exists(HISTORY_FILE):
        df_to_save.to_csv(HISTORY_FILE, index=False)
    else:
        df_to_save.to_csv(HISTORY_FILE, mode='a', header=False, index=False)
    
    return df_to_save, new_hash

# --- 5. å³æ ¼ãªäºˆå®Ÿé›†è¨ˆ (Strict Protocol) ---
def calculate_protocol_performance():
    if not os.path.exists(HISTORY_FILE):
        return pd.DataFrame(), "No Data"
    
    history = pd.read_csv(HISTORY_FILE)
    if history.empty: return pd.DataFrame(), "No Data"
    
    results = []
    
    # QQQãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    qqq = yf.Ticker("QQQ")
    # éå»ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªã®ã§é•·ã‚ã«å–ã‚‹
    qqq_hist = qqq.history(period="3mo") 
    
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªRun IDã”ã¨ã«å‡¦ç†
    run_ids = history['Run_ID'].unique()
    
    for rid in run_ids:
        run_data = history[history['Run_ID'] == rid]
        scan_time_str = run_data['Scan_Time'].iloc[0]
        scan_date = pd.to_datetime(scan_time_str).date()
        
        # ãƒ—ãƒ­ãƒˆã‚³ãƒ«: Entryã¯ã€Œç¿Œå–¶æ¥­æ—¥ã®å§‹å€¤ã€
        # ä»Šæ—¥ãŒã‚¹ã‚­ãƒ£ãƒ³æ—¥ãªã‚‰ã€ã¾ã ç¿Œæ—¥ã®ãƒ‡ãƒ¼ã‚¿ã¯ãªã„ -> Pending
        today = datetime.now().date()
        
        status = "Pending"
        avg_return = 0.0
        
        # ç°¡æ˜“åˆ¤å®š: ã‚¹ã‚­ãƒ£ãƒ³æ—¥ãŒä»Šæ—¥ãªã‚‰Pendingã€éå»ãªã‚‰è¨ˆç®—è©¦è¡Œ
        if scan_date >= today:
            status = "â³ Waiting for Next Open"
        else:
            # éå»ãƒ‡ãƒ¼ã‚¿å–å¾— (Batchå‡¦ç†æ¨å¥¨ã ãŒã€ã“ã“ã§ã¯å€‹åˆ¥å–å¾—)
            # å®Ÿéš›ã«ã¯ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åˆ¤å®šãŒå¿…è¦ã ãŒã€ç°¡æ˜“çš„ã«ã€Œã‚¹ã‚­ãƒ£ãƒ³æ—¥ã®æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ã€ã‚’æ¢ã™
            status = "Active/Closed"
            run_returns = []
            
            for _, row in run_data.iterrows():
                try:
                    # ã‚¹ã‚­ãƒ£ãƒ³æ—¥ä»¥é™ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    ticker = row['Ticker']
                    stock_hist = yf.Ticker(ticker).history(start=scan_date + timedelta(days=1))
                    
                    if stock_hist.empty:
                        continue # ãƒ‡ãƒ¼ã‚¿ãªã—
                        
                    # Entry: æœ€åˆã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã®Open
                    entry_price = stock_hist['Open'].iloc[0]
                    # Current/Exit: æœ€æ–°ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã®Close (ã¾ãŸã¯20æ—¥å¾Œã®Open)
                    current_price = stock_hist['Close'].iloc[-1]
                    
                    ret = (current_price - entry_price) / entry_price
                    run_returns.append(ret)
                except:
                    continue
            
            if run_returns:
                # å¹³å‡ãƒªã‚¿ãƒ¼ãƒ³ - ã‚³ã‚¹ãƒˆ
                avg_return = np.mean(run_returns) - COST_MODEL
        
        results.append({
            "Run_ID": rid,
            "Scan_Date": scan_date,
            "Status": status,
            "Protocol_Return": avg_return if status != "â³ Waiting for Next Open" else None,
            "Hash_Check": run_data['Record_Hash'].iloc[0][:8] + "..." # è¡¨ç¤ºç”¨
        })
        
    return pd.DataFrame(results), "OK"

# --- 6. UIæ§‹ç¯‰ ---
tab1, tab2 = st.tabs(["ğŸš€ Systematic Scanner", "â›“ï¸ Chained Audit Log"])

with tab1:
    st.title("ğŸ¦… Market Edge Pro (Blockchain Audit)")
    st.caption(f"Ver: {MODEL_VERSION} | Chain: Enabled | Protocol: Next-Open Entry")

    bench_price = fetch_market_context()
    st.metric("Context: QQQ Price", f"${bench_price:.2f}")

    with st.expander("ğŸ›¡ï¸ Security & Protocol Definition", expanded=True):
        st.markdown("""
        1.  **Chained Hashing:** å®Ÿè¡Œãƒ­ã‚°ã¯ã€Œå‰ã®è¡Œã®ãƒãƒƒã‚·ãƒ¥ã€ã‚’å«ã‚“ã§æš—å·åŒ–ã•ã‚Œã¾ã™ã€‚éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’1è¡Œã§ã‚‚æ”¹ã–ã‚“ã™ã‚‹ã¨ã€ãƒã‚§ãƒ¼ãƒ³ãŒå£Šã‚Œã¦æ¤œå‡ºã•ã‚Œã¾ã™ã€‚
        2.  **Strict Protocol:** æ¤œè¨¼ã¯ã€Œã‚¹ã‚­ãƒ£ãƒ³æ™‚ç‚¹ã®ä¾¡æ ¼ã€ã§ã¯ãªãã€**ã€Œç¿Œå–¶æ¥­æ—¥ã®å§‹å€¤(Open)ã€**ã«åŸºã¥ã„ã¦è¡Œã‚ã‚Œã¾ã™ï¼ˆå¾…æ©Ÿä¸­ã¯Pendingè¡¨ç¤ºï¼‰ã€‚
        3.  **Decay Model:** Spreadï¼ˆä¸ç¢ºå®Ÿæ€§ï¼‰ã«å¿œã˜ã¦ã€ã‚¹ã‚³ã‚¢ã‚’ `1/(1+Spread)` ã§æ»‘ã‚‰ã‹ã«æ¸›è¡°ã•ã›ã¾ã™ã€‚
        """)

    TARGETS = ["NVDA", "MSFT", "AAPL", "AMZN", "GOOGL", "META", "TSLA", "AVGO", "AMD", "PLTR", "ARM", "SMCI", "COIN", "CRWD", "LLY", "NVO", "COST", "NFLX", "INTC"]

    if st.button("RUN & CHAIN-LOG", type="primary"):
        raw_df = fetch_stock_data(TARGETS)
        if not raw_df.empty:
            portfolio_df, logs = build_portfolio(raw_df)
            final_df, block_hash = save_to_history(portfolio_df)
            
            st.subheader(f"ğŸ† Portfolio Generated (Block Hash: {block_hash[:12]}...)")
            
            if logs:
                for log in logs: st.warning(log)
            
            st.dataframe(
                final_df[['Ticker', 'Sector', 'Score', 'Spread', 'PEG_Val']]
                .style
                .format({'Score': '{:.0f}', 'Spread': '{:.1%}', 'PEG_Val': '{:.2f}'})
                .background_gradient(subset=['Score'], cmap='Greens'),
                use_container_width=True
            )
            st.success("âœ… Recorded to Chained Log. (Tamper Evident)")
        else:
            st.error("Data fetch failed.")

with tab2:
    st.header("â›“ï¸ Audit Trail & Performance")
    st.info("ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³æ§‹é€ ã§ä¿å­˜ã•ã‚ŒãŸãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿ã€ãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆç¿Œæ—¥å§‹å€¤ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼‰ã«åŸºã¥ã„ã¦æˆç¸¾ã‚’è¨ˆç®—ã—ã¾ã™ã€‚")
    
    if st.button("ğŸ”„ Audit Chain & Calc Returns"):
        audit_df, msg = calculate_protocol_performance()
        
        if not audit_df.empty:
            st.dataframe(
                audit_df.style
                .format({'Protocol_Return': '{:.2%}'})
                .applymap(lambda x: 'color: gray' if x is None else ('color: green' if x > 0 else 'color: red'), subset=['Protocol_Return']),
                use_container_width=True
            )
            st.caption("â€» 'Pending' ã®è¡Œã¯ã€ç¿Œå–¶æ¥­æ—¥ã®å§‹å€¤ãŒã¾ã ç™ºç”Ÿã—ã¦ã„ãªã„ãŸã‚ã€ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—ã‚’ä¿ç•™ã—ã¦ã„ã¾ã™ã€‚")
        else:
            st.write("No valid chain found.")
